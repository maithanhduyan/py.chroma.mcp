# Generated by Copilot
# ChromaDB MCP Server - Environment Variables Configuration
# Copy this file to .env and customize your settings

# ==================================================================
# EMBEDDING MODEL CONFIGURATION (PRIORITY 1)
# ==================================================================

# Primary embedding model name
# Examples:
# - sentence-transformers/all-MiniLM-L6-v2 (fast, lightweight)
# - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (Vietnamese support)
# - nomic-ai/nomic-embed-text-v1.5 (high quality)
# - text-embedding-3-small (OpenAI, requires API key)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Alternative environment variable names (same function)
# MCP_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# CHROMA_EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5

# Fallback models (comma-separated, will be tried if primary fails)
EMBEDDING_FALLBACK_MODELS=sentence-transformers/all-MiniLM-L6-v2,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# ==================================================================
# DEVICE CONFIGURATION
# ==================================================================

# Device preference: auto, cpu, cuda, mps
# - auto: automatically detect best device
# - cpu: force CPU usage
# - cuda: force NVIDIA GPU (if available)
# - mps: force Apple Silicon GPU (if available)
EMBEDDING_DEVICE=auto

# ==================================================================
# CACHE AND STORAGE
# ==================================================================

# Directory to cache downloaded models (saves time on subsequent runs)
EMBEDDING_CACHE_DIR=./models_cache/

# Alternative cache directory names
# SENTENCE_TRANSFORMERS_HOME=./models_cache/
# MODEL_CACHE_DIR=./models_cache/

# ChromaDB data persistence directory
CHROMA_PERSIST_DIR=./chroma_db/

# ==================================================================
# PERFORMANCE TUNING
# ==================================================================

# Batch processing size (higher = more memory, faster processing)
EMBEDDING_BATCH_SIZE=32

# Maximum items in embedding cache
EMBEDDING_MAX_CACHE_SIZE=1000

# Request timeout for model operations (seconds)
EMBEDDING_TIMEOUT=60

# ==================================================================
# CHROMADB CONFIGURATION
# ==================================================================

# ChromaDB server host and port
CHROMA_HOST=localhost
CHROMA_PORT=8000

# ==================================================================
# OPENAI CONFIGURATION (if using OpenAI embeddings)
# ==================================================================

# OpenAI API key (required for OpenAI models)
# OPENAI_API_KEY=your_openai_api_key_here

# OpenAI organization (optional)
# OPENAI_ORG_ID=your_org_id_here

# ==================================================================
# LOGGING AND DEBUG
# ==================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Enable detailed performance metrics
ENABLE_METRICS=true

# Enable memory usage tracking
ENABLE_MEMORY_TRACKING=true

# ==================================================================
# VIETNAMESE TEXT PROCESSING
# ==================================================================

# Text chunk size for Vietnamese documents
VIETNAMESE_CHUNK_SIZE=400

# Text overlap between chunks
VIETNAMESE_CHUNK_OVERLAP=50

# Enable Vietnamese text normalization
ENABLE_VIETNAMESE_NORMALIZATION=true

# ==================================================================
# SECURITY
# ==================================================================

# Trust remote code in model loading (use with caution)
TRUST_REMOTE_CODE=true

# Disable network access for model loading (use only cached models)
# OFFLINE_MODE=false

# ==================================================================
# EXAMPLE CONFIGURATIONS
# ==================================================================

# Fast Development Setup (minimal resource usage)
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_DEVICE=cpu
# EMBEDDING_BATCH_SIZE=16

# Production Vietnamese Setup (good balance)
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# EMBEDDING_DEVICE=auto
# EMBEDDING_BATCH_SIZE=32

# High Performance Setup (requires good hardware)
# EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5
# EMBEDDING_DEVICE=cuda
# EMBEDDING_BATCH_SIZE=64

# OpenAI Setup (requires API key)
# EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_API_KEY=your_key_here
# EMBEDDING_BATCH_SIZE=100
